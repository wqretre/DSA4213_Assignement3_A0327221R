# DSA4213_Assignement3_A0327221R
# BERT Fine-tuning and LoRA on GoEmotions

This repository contains code for fine-tuning and parameter-efficient tuning (LoRA) of **BERT-base-uncased** on the **GoEmotions** dataset for multi-label emotion classification.  
It compares **Full Fine-tuning** and **LoRA** in terms of training efficiency and performance.

---

## ğŸ“‚ Project Structure
goemotions-finetune/
â”œâ”€â”€ main.py # One-click entry point for both experiments
â”œâ”€â”€ full_finetune.py # Full fine-tuning logic
â”œâ”€â”€ lora_finetune.py # LoRA fine-tuning logic
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # This file
â””â”€â”€ results/ # Saved models, logs, and loss curves

| Item | Description |
|------|--------------|
| **Dataset** | [GoEmotions (simplified)](https://huggingface.co/datasets/go_emotions) |
| **Model** | `bert-base-uncased` |
| **Task** | Multi-label emotion classification |
| **Methods** | Full Fine-tuning and LoRA |
| **Metrics** | F1 score, Per-label Accuracy, Subset Accuracy, Hamming Loss |

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/goemotions-finetune.git
cd goemotions-finetune
